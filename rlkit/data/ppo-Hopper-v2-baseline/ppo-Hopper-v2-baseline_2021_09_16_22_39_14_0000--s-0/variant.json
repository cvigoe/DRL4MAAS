{
  "algorithm": "PPO",
  "algorithm_kwargs": {
    "batch_size": 256,
    "clear_buffer_every_train_loop": true,
    "max_path_length": 1000,
    "min_num_steps_before_training": 0,
    "num_epochs": 3000,
    "num_eval_steps_per_epoch": 1000,
    "num_expl_steps_per_train_loop": 2048,
    "num_train_loops_per_epoch": 10,
    "num_trains_per_train_loop": 100
  },
  "layer_size": 256,
  "policy_kwargs": {
    "std": null
  },
  "replay_buffer_size": 1000000,
  "target_kwargs": {
    "target_lookahead": 15,
    "tdlambda": 0.95
  },
  "trainer_kwargs": {
    "discount": 0.99,
    "epsilon": 0.2,
    "policy_lr": 0.0003,
    "val_lr": 0.0003
  },
  "version": "normal"
}